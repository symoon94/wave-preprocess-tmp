{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Test.ipynb",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/symoon94/wave-preprocess-tmp/blob/master/conv_ae_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vy-HbF64Imsq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import os\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_otGnN_JmbZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
        "X_train_full = X_train_full.astype(np.float32) / 255\n",
        "X_test = X_test.astype(np.float32) / 255\n",
        "X_train, X_valid = X_train_full[:-5000], X_train_full[-5000:]\n",
        "y_train, y_valid = y_train_full[:-5000], y_train_full[-5000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LyMn-0PivkM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "import numpy as np\n",
        "\n",
        "def process_image(image, target_shape):\n",
        "    \"\"\"Given an image, process it and return the array.\"\"\"\n",
        "    # Load the image.\n",
        "    h, w, _ = target_shape\n",
        "    image = load_img(image, target_size=(h, w))\n",
        "\n",
        "    # Turn it into numpy, normalize and return.\n",
        "    img_arr = img_to_array(image)\n",
        "    x = (img_arr / 255.).astype(np.float32)\n",
        "\n",
        "class threadsafe_iterator:\n",
        "    def __init__(self, iterator):\n",
        "        self.iterator = iterator\n",
        "        self.lock = threading.Lock()\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        with self.lock:\n",
        "            return next(self.iterator)\n",
        "\n",
        "def threadsafe_generator(func):\n",
        "    \"\"\"Decorator\"\"\"\n",
        "    def gen(*a, **kw):\n",
        "        return threadsafe_iterator(func(*a, **kw))\n",
        "    return gen\n",
        "\n",
        "class DataSet():\n",
        "\n",
        "    def __init__(self, seq_length=40, class_limit=None, image_shape=(224, 224, 3)):\n",
        "        \"\"\"Constructor.\n",
        "        seq_length = (int) the number of frames to consider\n",
        "        class_limit = (int) number of classes to limit the data to.\n",
        "            None = no limit.\n",
        "        \"\"\"\n",
        "        self.seq_length = seq_length\n",
        "        self.class_limit = class_limit\n",
        "        self.sequence_path = os.path.join('data', 'sequences')\n",
        "        self.max_frames = 300  # max number of frames a video can have for us to use it\n",
        "\n",
        "        # Get the data.\n",
        "        self.data = self.get_data()\n",
        "\n",
        "        # Get the classes.\n",
        "        self.classes = self.get_classes()\n",
        "\n",
        "        # Now do some minor data cleaning.\n",
        "        self.data = self.clean_data()\n",
        "\n",
        "        self.image_shape = image_shape\n",
        "\n",
        "    @staticmethod\n",
        "    def get_data():\n",
        "        \"\"\"Load our data from file.\"\"\"\n",
        "        with open(os.path.join('/content', 'data_file.csv'), 'r') as fin:\n",
        "            reader = csv.reader(fin)\n",
        "            data = list(reader)\n",
        "\n",
        "        return data\n",
        "\n",
        "    def clean_data(self):\n",
        "        \"\"\"Limit samples to greater than the sequence length and fewer\n",
        "        than N frames. Also limit it to classes we want to use.\"\"\"\n",
        "        data_clean = []\n",
        "        for item in self.data:\n",
        "            if int(item[3]) >= self.seq_length and int(item[3]) <= self.max_frames \\\n",
        "                    and item[1] in self.classes:\n",
        "                data_clean.append(item)\n",
        "\n",
        "        return data_clean\n",
        "\n",
        "    def get_classes(self):\n",
        "        \"\"\"Extract the classes from our data. If we want to limit them,\n",
        "        only return the classes we need.\"\"\"\n",
        "        classes = []\n",
        "        for item in self.data:\n",
        "            if item[1] not in classes:\n",
        "                classes.append(item[1])\n",
        "\n",
        "        # Sort them.\n",
        "        classes = sorted(classes)\n",
        "\n",
        "        # Return.\n",
        "        if self.class_limit is not None:\n",
        "            return classes[:self.class_limit]\n",
        "        else:\n",
        "            return classes\n",
        "\n",
        "    def get_class_one_hot(self, class_str):\n",
        "        \"\"\"Given a class as a string, return its number in the classes\n",
        "        list. This lets us encode and one-hot it for training.\"\"\"\n",
        "        # Encode it first.\n",
        "        label_encoded = self.classes.index(class_str)\n",
        "\n",
        "        # Now one-hot it.\n",
        "        label_hot = to_categorical(label_encoded, len(self.classes))\n",
        "\n",
        "        assert len(label_hot) == len(self.classes)\n",
        "\n",
        "        return label_hot\n",
        "\n",
        "    def split_train_test(self):\n",
        "        \"\"\"Split the data into train and test groups.\"\"\"\n",
        "        train = []\n",
        "        test = []\n",
        "        for item in self.data:\n",
        "            if item[0] == 'train':\n",
        "                train.append(item)\n",
        "            else:\n",
        "                test.append(item)\n",
        "        return train, test\n",
        "\n",
        "    def get_all_sequences_in_memory(self, train_test, data_type):\n",
        "        \"\"\"\n",
        "        This is a mirror of our generator, but attempts to load everything into\n",
        "        memory so we can train way faster.\n",
        "        \"\"\"\n",
        "        # Get the right dataset.\n",
        "        train, test = self.split_train_test()\n",
        "        data = train if train_test == 'train' else test\n",
        "\n",
        "        print(\"Loading %d samples into memory for %sing.\" % (len(data), train_test))\n",
        "\n",
        "        X, y = [], []\n",
        "        for row in data:\n",
        "\n",
        "            if data_type == 'images':\n",
        "                frames = self.get_frames_for_sample(row)\n",
        "                frames = self.rescale_list(frames, self.seq_length)\n",
        "\n",
        "                # Build the image sequence\n",
        "                sequence = self.build_image_sequence(frames)\n",
        "\n",
        "            else:\n",
        "                sequence = self.get_extracted_sequence(data_type, row)\n",
        "\n",
        "                if sequence is None:\n",
        "                    print(\"Can't find sequence. Did you generate them?\")\n",
        "                    raise\n",
        "\n",
        "            X.append(sequence)\n",
        "            y.append(self.get_class_one_hot(row[1]))\n",
        "\n",
        "        return np.array(X), np.array(y)\n",
        "\n",
        "    @threadsafe_generator\n",
        "    def frame_generator(self, batch_size, train_test, data_type):\n",
        "        \"\"\"Return a generator that we can use to train on. There are\n",
        "        a couple different things we can return:\n",
        "        data_type: 'features', 'images'\n",
        "        \"\"\"\n",
        "        # Get the right dataset for the generator.\n",
        "        train, test = self.split_train_test()\n",
        "        data = train if train_test == 'train' else test\n",
        "\n",
        "        print(\"Creating %s generator with %d samples.\" % (train_test, len(data)))\n",
        "\n",
        "        while 1:\n",
        "            X, y = [], []\n",
        "\n",
        "            # Generate batch_size samples.\n",
        "            for _ in range(batch_size):\n",
        "                # Reset to be safe.\n",
        "                sequence = None\n",
        "\n",
        "                # Get a random sample.\n",
        "                sample = random.choice(data)\n",
        "\n",
        "                # Check to see if we've already saved this sequence.\n",
        "                if data_type is \"images\":\n",
        "                    # Get and resample frames.\n",
        "                    frames = self.get_frames_for_sample(sample)\n",
        "                    frames = self.rescale_list(frames, self.seq_length)\n",
        "\n",
        "                    # Build the image sequence\n",
        "                    sequence = self.build_image_sequence(frames)\n",
        "                else:\n",
        "                    # Get the sequence from disk.\n",
        "                    sequence = self.get_extracted_sequence(data_type, sample)\n",
        "\n",
        "                    if sequence is None:\n",
        "                        raise ValueError(\"Can't find sequence. Did you generate them?\")\n",
        "\n",
        "                X.append(sequence)\n",
        "                y.append(self.get_class_one_hot(sample[1]))\n",
        "\n",
        "            yield np.array(X), np.array(y)\n",
        "\n",
        "    def build_image_sequence(self, frames):\n",
        "        \"\"\"Given a set of frames (filenames), build our sequence.\"\"\"\n",
        "        return [process_image(x, self.image_shape) for x in frames]\n",
        "\n",
        "    def get_extracted_sequence(self, data_type, sample):\n",
        "        \"\"\"Get the saved extracted features.\"\"\"\n",
        "        filename = sample[2]\n",
        "        path = os.path.join(self.sequence_path, filename + '-' + str(self.seq_length) + \\\n",
        "            '-' + data_type + '.npy')\n",
        "        if os.path.isfile(path):\n",
        "            return np.load(path)\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def get_frames_by_filename(self, filename, data_type):\n",
        "        \"\"\"Given a filename for one of our samples, return the data\n",
        "        the model needs to make predictions.\"\"\"\n",
        "        # First, find the sample row.\n",
        "        sample = None\n",
        "        for row in self.data:\n",
        "            if row[2] == filename:\n",
        "                sample = row\n",
        "                break\n",
        "        if sample is None:\n",
        "            raise ValueError(\"Couldn't find sample: %s\" % filename)\n",
        "\n",
        "        if data_type == \"images\":\n",
        "            # Get and resample frames.\n",
        "            frames = self.get_frames_for_sample(sample)\n",
        "            frames = self.rescale_list(frames, self.seq_length)\n",
        "            # Build the image sequence\n",
        "            sequence = self.build_image_sequence(frames)\n",
        "        else:\n",
        "            # Get the sequence from disk.\n",
        "            sequence = self.get_extracted_sequence(data_type, sample)\n",
        "\n",
        "            if sequence is None:\n",
        "                raise ValueError(\"Can't find sequence. Did you generate them?\")\n",
        "\n",
        "        return sequence\n",
        "\n",
        "    @staticmethod\n",
        "    def get_frames_for_sample(sample):\n",
        "        \"\"\"Given a sample row from the data file, get all the corresponding frame\n",
        "        filenames.\"\"\"\n",
        "        path = os.path.join('data', sample[0], sample[1])\n",
        "        filename = sample[2]\n",
        "        images = sorted(glob.glob(os.path.join(path, filename + '*jpg')))\n",
        "        return images\n",
        "\n",
        "    @staticmethod\n",
        "    def get_filename_from_image(filename):\n",
        "        parts = filename.split(os.path.sep)\n",
        "        return parts[-1].replace('.jpg', '')\n",
        "\n",
        "    @staticmethod\n",
        "    def rescale_list(input_list, size):\n",
        "        \"\"\"Given a list and a size, return a rescaled/samples list. For example,\n",
        "        if we want a list of size 5 and we have a list of size 25, return a new\n",
        "        list of size five which is every 5th element of the origina list.\"\"\"\n",
        "        assert len(input_list) >= size\n",
        "\n",
        "        # Get the number to skip between iterations.\n",
        "        skip = len(input_list) // size\n",
        "\n",
        "        # Build our new output.\n",
        "        output = [input_list[i] for i in range(0, len(input_list), skip)]\n",
        "\n",
        "        # Cut off the last one if needed.\n",
        "        return output[:size]\n",
        "\n",
        "    def print_class_from_prediction(self, predictions, nb_to_return=5):\n",
        "        \"\"\"Given a prediction, print the top classes.\"\"\"\n",
        "        # Get the prediction for each label.\n",
        "        label_predictions = {}\n",
        "        for i, label in enumerate(self.classes):\n",
        "            label_predictions[label] = predictions[i]\n",
        "\n",
        "        # Now sort them.\n",
        "        sorted_lps = sorted(\n",
        "            label_predictions.items(),\n",
        "            key=operator.itemgetter(1),\n",
        "            reverse=True\n",
        "        )\n",
        "\n",
        "        # And return the top N.\n",
        "        for i, class_prediction in enumerate(sorted_lps):\n",
        "            if i > nb_to_return - 1 or class_prediction[1] == 0.0:\n",
        "                break\n",
        "            print(\"%s: %.2f\" % (class_prediction[0], class_prediction[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aYEu_qyivm3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing import image\n",
        "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input\n",
        "import numpy as np\n",
        "\n",
        "class Extractor():\n",
        "    def __init__(self, weights=None):\n",
        "        \"\"\"Either load pretrained from imagenet, or load our saved\n",
        "        weights from our own training.\"\"\"\n",
        "\n",
        "        self.weights = weights  # so we can check elsewhere which model\n",
        "\n",
        "        if weights is None:\n",
        "            # Get model with pretrained weights.\n",
        "            base_model = InceptionV3(\n",
        "                weights='imagenet',\n",
        "                include_top=True\n",
        "            )\n",
        "\n",
        "            # We'll extract features at the final pool layer.\n",
        "            self.model = Model(\n",
        "                inputs=base_model.input,\n",
        "                outputs=base_model.get_layer('avg_pool').output\n",
        "            )\n",
        "\n",
        "        else:\n",
        "            # Load the model first.\n",
        "            self.model = load_model(weights)\n",
        "\n",
        "            # Then remove the top so we get features not predictions.\n",
        "            # From: https://github.com/fchollet/keras/issues/2371\n",
        "            self.model.layers.pop()\n",
        "            self.model.layers.pop()  # two pops to get to pool layer\n",
        "            self.model.outputs = [self.model.layers[-1].output]\n",
        "            self.model.output_layers = [self.model.layers[-1]]\n",
        "            self.model.layers[-1].outbound_nodes = []\n",
        "\n",
        "    def extract(self, image_path):\n",
        "        img = image.load_img(image_path, target_size=(299, 299))\n",
        "        x = image.img_to_array(img)\n",
        "        x = np.expand_dims(x, axis=0)\n",
        "        x = preprocess_input(x)\n",
        "\n",
        "        # Get the prediction.\n",
        "        features = self.model.predict(x)\n",
        "\n",
        "        if self.weights is None:\n",
        "            # For imagenet/default network:\n",
        "            features = features[0]\n",
        "        else:\n",
        "            # For loaded network:\n",
        "            features = features[0]\n",
        "\n",
        "        return features\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPSPNlXhiTNP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq_length = 10\n",
        "class_limit = None  # Number of classes to extract. Can be 1-101 or None for all.\n",
        "\n",
        "# Get the dataset.\n",
        "data = DataSet(seq_length=seq_length, class_limit=class_limit)\n",
        "\n",
        "# get the model.\n",
        "model = Extractor()\n",
        "\n",
        "# Loop through data.\n",
        "pbar = tqdm(total=len(data.data))\n",
        "for video in data.data:\n",
        "\n",
        "    # Get the path to the sequence for this video.\n",
        "    path = os.path.join('data', 'sequences', video[2] + '-' + str(seq_length) + \\\n",
        "        '-features')  # numpy will auto-append .npy\n",
        "\n",
        "    # Check if we already have it.\n",
        "    if os.path.isfile(path + '.npy'):\n",
        "        pbar.update(1)\n",
        "        continue\n",
        "\n",
        "    # Get the frames for this video.\n",
        "    frames = data.get_frames_for_sample(video)\n",
        "\n",
        "    # Now downsample to just the ones we need.\n",
        "    frames = data.rescale_list(frames, seq_length)\n",
        "\n",
        "    # Now loop through and extract features to build the sequence.\n",
        "    sequence = []\n",
        "    for image in frames:\n",
        "        features = model.extract(image)\n",
        "        sequence.append(features)\n",
        "\n",
        "    # Save the sequence.\n",
        "    np.save(path, sequence)\n",
        "\n",
        "    pbar.update(1)\n",
        "\n",
        "pbar.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwIuuhXikJWa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tpFK43JkJaN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzdWn9vukJTf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qI_knofYJoov",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv_encoder = keras.models.Sequential([\n",
        "    keras.layers.Reshape([28, 28, 1], input_shape=[28, 28]),\n",
        "    keras.layers.Conv2D(16, kernel_size=3, padding=\"SAME\", activation=\"selu\"),\n",
        "    keras.layers.MaxPool2D(pool_size=2),\n",
        "    keras.layers.Conv2D(32, kernel_size=3, padding=\"SAME\", activation=\"selu\"),\n",
        "    keras.layers.MaxPool2D(pool_size=2),\n",
        "    keras.layers.Conv2D(64, kernel_size=3, padding=\"SAME\", activation=\"selu\"),\n",
        "    keras.layers.MaxPool2D(pool_size=2)\n",
        "])\n",
        "conv_decoder = keras.models.Sequential([\n",
        "    keras.layers.Conv2DTranspose(32, kernel_size=3, strides=2, padding=\"VALID\", activation=\"selu\",\n",
        "                                 input_shape=[3, 3, 64]),\n",
        "    keras.layers.Conv2DTranspose(16, kernel_size=3, strides=2, padding=\"SAME\", activation=\"selu\"),\n",
        "    keras.layers.Conv2DTranspose(1, kernel_size=3, strides=2, padding=\"SAME\", activation=\"sigmoid\"),\n",
        "    keras.layers.Reshape([28, 28])\n",
        "])\n",
        "conv_ae = keras.models.Sequential([conv_encoder, conv_decoder])\n",
        "\n",
        "conv_ae.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.SGD(lr=1.0),\n",
        "                metrics=['accuracy'])\n",
        "history = conv_ae.fit(X_train, X_train, epochs=5, validation_data=(X_valid, X_valid))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yP8Tsex4J-3s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv_encoder.summary()\n",
        "conv_decoder.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWVngC8qd-cX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
        "\n",
        "def plot_image(image):\n",
        "    plt.imshow(image, cmap=\"binary\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "def show_pig(model, images=X_valid, n_images=10):\n",
        "    reconstructions = model.predict(images[:n_images])\n",
        "    fig = plt.figure(figsize=(n_images * 1.5, 3))\n",
        "    for image_index in range(n_images):\n",
        "        plt.subplot(2, n_images, 1 + image_index)\n",
        "        plot_image(images[image_index])\n",
        "        plt.subplot(2, n_images, 1 + n_images + image_index)\n",
        "        plot_image(reconstructions[image_index])\n",
        "\n",
        "show_pig(conv_ae)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5siZ7V0eAUj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import model_from_json\n",
        "from keras.models import load_model\n",
        "\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "  print()\n",
        "  json_file.write(model_json)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}